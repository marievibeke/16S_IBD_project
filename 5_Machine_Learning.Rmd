---
title: "Machine Learning"
output:
  github_document:
    toc: true
editor_options:
  chunk_output_type: console
---

## Read in packages and data
```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(phyloseq)
library(ggpubr)
library(randomForest)
library(caret)
library(glmnet)
library(ROCR)

packageVersion("tidyverse")
packageVersion("ggplot2")
packageVersion("dplyr")
packageVersion("phyloseq")
packageVersion("ggpubr")
packageVersion("randomForest")
packageVersion("caret")
packageVersion("glmnet")
packageVersion("ROCR")

path <- "C:/Users/FX76TZ/OneDrive - Aalborg Universitet/Mikrobiom korrelation/"
ps_relab <- readRDS(paste0(path, "data/IBD_project/ps_total_relab.rds"))
```

## Random Forest with balanced datasets:
### Prepare a test and a validation dataset:
```{r}
#Reduce the number to be tested! 
ps_sub <- subset_samples(ps_relab, !is.na(Disease))
ps_sub <- subset_samples(ps_sub, !is.na(geo_loc_name_country))
ps_sub <- subset_samples(ps_sub, !is.na(Host_Age))
ps_sub <- subset_samples(ps_sub, !is.na(host_sex))

genus <- as.data.frame(as.matrix(otu_table(ps_sub)))
genus[1:5, 1:5]
#Remove columns with no count in any sample:
genus1 <- genus[,colSums(genus)!=0]

#Remove columns, where the genus is present in less than 10% of the samples:
sum(sapply(genus1, function(x) sum(x==0)) / dim(genus1)[1]>0.90)
genus <- genus1[, sapply(genus1, function(x) sum(x==0)) / dim(genus1)[1]<0.90]

ps_relab_reduced <- phyloseq(otu_table(genus, taxa_are_rows=F), sample_data(ps_sub), tax_table(ps_sub))

#Balance datasets based on disease!
meta_data <- as.data.frame(as.matrix(sample_data(ps_relab_reduced)))
meta_CD <- meta_data %>% filter(Disease !="UC")
meta_UC <- meta_data %>% filter(Disease !="CD")

#Remove projects with 0 IBD cases or 0 HC:
meta_CD %>% dplyr::group_by(BioProject) %>% summarize(CD = sum(Disease == "CD"), HC = sum(Disease == "HC"))
meta_CD <- meta_CD %>% filter(!(BioProject %in% c("PRJDB4871", "PRJEB18780", "PRJEB33031", "PRJNA380944", "PRJNA418765", "PRJNA610934", "PRJNA679275")))

set.seed(0)
new_CD <- data.frame()
for (i in unique(meta_CD$BioProject)){
  sub_CD <- meta_CD %>% filter(BioProject==i) %>% filter(Disease == "CD")
  sub_HC <- meta_CD %>% filter(BioProject==i) %>% filter(Disease == "HC")
  if (nrow(sub_CD) == nrow(sub_HC)){
    new_CD <- rbind(new_CD,sub_CD)
    new_CD <- rbind(new_CD,sub_HC)
  } else if (nrow(sub_CD) < nrow(sub_HC)){
    sub_HC <- sample_n(sub_HC, nrow(sub_CD))
    new_CD <- rbind(new_CD,sub_CD)
    new_CD <- rbind(new_CD,sub_HC)
  } else {
    sub_CD <- sample_n(sub_CD, nrow(sub_HC))
    new_CD <- rbind(new_CD,sub_CD)
    new_CD <- rbind(new_CD,sub_HC)    
  }
}

meta_UC %>% dplyr::group_by(BioProject) %>% summarize(UC = sum(Disease == "UC"), HC = sum(Disease == "HC"))
meta_UC <- meta_UC %>% filter(!(BioProject %in% c("PRJEB18780", "PRJEB3206", "PRJEB7166", "PRJNA380944", "PRJNA515212", "PRJNA646271")))

set.seed(0)
new_UC <- data.frame()
for (i in unique(meta_UC$BioProject)){
  sub_UC <- meta_UC %>% filter(BioProject==i) %>% filter(Disease == "UC")
  sub_HC <- meta_UC %>% filter(BioProject==i) %>% filter(Disease == "HC")
  if (nrow(sub_UC) == nrow(sub_HC)){
    new_UC <- rbind(new_UC,sub_UC)
    new_UC <- rbind(new_UC,sub_HC)
  } else if (nrow(sub_UC) < nrow(sub_HC)){
    sub_HC <- sample_n(sub_HC, nrow(sub_UC))
    new_UC <- rbind(new_UC,sub_UC)
    new_UC <- rbind(new_UC,sub_HC)
  } else {
    sub_UC <- sample_n(sub_UC, nrow(sub_HC))
    new_UC <- rbind(new_UC,sub_UC)
    new_UC <- rbind(new_UC,sub_HC)  
  }
}

ps_CD <- subset_samples(ps_relab_reduced, Run %in% new_CD$Run)
ps_UC <- subset_samples(ps_relab_reduced, Run %in% new_UC$Run)

#Split dataset randomly into train and validation:
otu <- as.data.frame(as.matrix(otu_table(ps_CD)))
meta <- sample_data(ps_CD)
meta <- as.data.frame(as.matrix(meta)) %>% dplyr::select(Disease, geo_loc_name_country_continent, Instrument, LibraryLayout, X16s_region, Host_Age, host_sex, N)
df_CD <- cbind(otu, meta)
df_CD$N <- as.numeric(df_CD$N)
df_CD$Host_Age <- as.numeric(df_CD$Host_Age)

otu <- as.data.frame(as.matrix(otu_table(ps_UC)))
meta <- sample_data(ps_UC)
meta <- as.data.frame(as.matrix(meta)) %>% dplyr::select(Disease, geo_loc_name_country_continent, Instrument, LibraryLayout, X16s_region, Host_Age, host_sex, N)
df_UC <- cbind(otu, meta)
df_UC$N <- as.numeric(df_UC$N)
df_UC$Host_Age <- as.numeric(df_UC$Host_Age)

set.seed(0)
ind <- sample(2, nrow(df_CD), replace = TRUE, prob = c(0.7, 0.3))
train_CD <- df_CD[ind==1,]
test_CD <- df_CD[ind==2,]

set.seed(0)
ind <- sample(2, nrow(df_UC), replace = TRUE, prob = c(0.7, 0.3))
train_UC <- df_UC[ind==1,]
test_UC <- df_UC[ind==2,]
```

### Random Forest:
```{r}
## Start with CD:

#Baseline model with default settings:
control <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"

#Search for best mtry and ntree:
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes

# train model
tunegrid <- expand.grid(.mtry=c(15, 20, 25, 30, 35), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom <- train(Disease~., data=train_CD, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom$results$Accuracy

tunegrid <- expand.grid(.mtry=c(40, 45, 50, 55, 60, 65, 70, 75), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom1 <- train(Disease~., data=train_CD, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom1$results$Accuracy

tunegrid <- expand.grid(.mtry=c(80, 90, 100, 110, 120, 130, 140, 150), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom2 <- train(Disease~., data=train_CD, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom2$results$Accuracy

#Last grid search  - finer!:
tunegrid <- expand.grid(.mtry=seq(from =74, to = 96, by =2), .ntree=c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500))
set.seed(0)
custom3 <- train(Disease~., data=train_CD, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom3$results$Accuracy

#Results from grid search:
df <- data.frame(mtry = c(rep(15,4), rep(20,4), rep(25,4), rep(30,4), rep(35,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),5)), Accuracy = c(0.7314203, 0.7342536, 0.7370314, 0.7230821, 0.7355314, 0.7343647, 0.7314758, 0.7313599, 0.7327488, 0.7271932, 0.7258599, 0.7245266, 0.7244710, 0.7285266, 0.7285821, 0.7259155, 0.7355821, 0.7341377, 0.7326932, 0.7245266))

df1 <- data.frame(mtry = c(rep(40,4), rep(45,4), rep(50,4), rep(55,4), rep(60,4), rep(65,4), rep(70,4), rep(75,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),8)), Accuracy = c(0.7327488, 0.7285821, 0.7326932, 0.7341932, 0.7368599, 0.7340821, 0.7383599, 0.7314155, 0.7383043, 0.7383043, 0.7314710, 0.7313599, 0.7341377, 0.7368599, 0.7272488, 0.7369155, 0.7328043, 0.7285821, 0.7244710, 0.7368599, 0.7300266, 0.7341377, 0.7369710, 0.7299710, 0.7313599, 0.7383043, 0.7383043, 0.7327488, 0.7383043, 0.7327488, 0.7369710, 0.7396932))

df2 <- data.frame(mtry = c(rep(80,4), rep(90,4), rep(100,4), rep(110,4), rep(120,4), rep(130,4), rep(140,4), rep(150,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),8)), Accuracy = c(0.7382488, 0.7369710, 0.7327488, 0.7299710, 0.7424155, 0.7410821, 0.7368599, 0.7369155, 0.7313599, 0.7368599, 0.7355266, 0.7340821, 0.7383043, 0.7383043, 0.7299710, 0.7326932, 0.7340821, 0.7313043, 0.7368599, 0.7326377, 0.7355821, 0.7395821, 0.7354710, 0.7354155, 0.7368599, 0.7340821, 0.7368043, 0.7340821, 0.7382488, 0.7326932, 0.7354710, 0.7368599))

df3 <- data.frame(mtry = c(rep(74, 8), rep(76, 8), rep(78, 8), rep(80, 8), rep(82, 8), rep(84, 8), rep(86, 8), rep(88, 8), rep(90, 8), rep(92, 8), rep(94, 8), rep(96, 8)), ntree = as.factor(rep(c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500), 12)), Accuracy = c(0.7314710, 0.7314155, 0.7396932, 0.7326932, 0.7342488, 0.7383043, 0.7341377, 0.7382488, 0.7395821, 0.7354710, 0.7369155, 0.7327488, 0.7341377, 0.7382488, 0.7383043, 0.7369155, 0.7368599, 0.7355266, 0.7299710, 0.7285821, 0.7300266, 0.7341377, 0.7328043, 0.7382488, 0.7273599, 0.7465821, 0.7340821, 0.7383043, 0.7368599, 0.7355266, 0.7369155, 0.7355266, 0.7327488, 0.7396932, 0.7396932, 0.7355821, 0.7383043, 0.7341377, 0.7327488, 0.7328043, 0.7355266, 0.7383043, 0.7327488, 0.7341377, 0.7396932, 0.7354710, 0.7396932, 0.7355266, 0.7383043, 0.7341932, 0.7355266, 0.7341377, 0.7369155, 0.7313599, 0.7327488, 0.7341377, 0.7313599, 0.7341377, 0.7369155, 0.7314155, 0.7395821, 0.7424155, 0.7340821, 0.7341377, 0.7369155, 0.7328043, 0.7383043, 0.7368599, 0.7396932, 0.7355266, 0.7369155, 0.7383043, 0.7383043, 0.7424155, 0.7410266, 0.7410266, 0.7438043, 0.7327488, 0.7409155, 0.7383043, 0.7383043, 0.7299155, 0.7369155, 0.7326932, 0.7299710, 0.7368043, 0.7327488, 0.7368599, 0.7424710, 0.7354155, 0.7327488, 0.7313043, 0.7299155, 0.7368599, 0.7424155, 0.7313599))

df <- rbind(df, df1, df2)
ggplot(df)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()+geom_vline(xintercept = 74, linetype = "dashed")+geom_vline(xintercept = 96, linetype = "dashed")
df[which.max(df$Accuracy),]

ggplot(df3)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()
df3[which.max(df3$Accuracy),]

best_mtry <- 80
best_ntree <- 1000

#After selecting the optimal model: Fit and investigate!
#RF:
set.seed(0)
old_colnames <- colnames(train_CD)
colnames(train_CD) <- paste0("col_", seq(ncol(train_CD))) 
train_CD$col_145 <- as.factor(train_CD$col_145)
rf <- randomForest(col_145~., data=train_CD, mtry=best_mtry, ntree = best_ntree) 
print(rf)

#Prediction and confusion matrix - training data:
p1 <- predict(rf, train_CD)
confusionMatrix(p1, train_CD$col_145)

#Prediction and confusion matrix - test data:
colnames(test_CD) <- paste0("col_", seq(ncol(test_CD))) 
test_CD$col_145 <- as.factor(test_CD$col_145)
p2 <- predict(rf, test_CD)
confusionMatrix(p2, test_CD$col_145)

#Number of nodes and variable importance:
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")

varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
imp_CD <- as.data.frame(importance(rf))
old_colnames <- old_colnames[c(1:144, 146:152)]
imp_CD$bugs <- old_colnames

best10_CD <- imp_CD[order(-imp_CD$MeanDecreaseGini),]
best10_CD <- best10_CD[1:10,]

# Model accuracy
observed.classes <- test_CD$col_145
accuracy <- mean(p2 == observed.classes) # 0.7731959

res_CD <- data.frame(p2, observed.classes)
res_CD <- res_CD %>% mutate(type = ifelse(p2=="CD" & observed.classes=="CD", "TP", ifelse(p2=="CD" & observed.classes=="HC", "FP", ifelse(p2=="HC" & observed.classes=="CD", "FN", "TN"))))

precision <- sum(res_CD$type=="TP") / (sum(res_CD$type=="FP") + sum(res_CD$type=="TP")) #Pr(disease|positive)
sensitivity <- sum(res_CD$type=="TP") / (sum(res_CD$type=="TP") + sum(res_CD$type=="FN")) #Pr(positive|disease)
specificity <- sum(res_CD$type=="TN") / (sum(res_CD$type=="TN") + sum(res_CD$type=="FP")) #Pr(negative|no disease)

accuracy #0.7731959
precision #0.7659574
sensitivity #0.7659574
specificity #0.78

#Make ROC curve:
predictions <- as.data.frame(predict(rf, test_CD, type = "prob"))
obs <- ifelse(observed.classes=="HC", 0, 1)
pred <- prediction(predictions$CD, obs)
perf <- performance(pred,"tpr","fpr")

roc_df <- data.frame(FPR = perf@x.values, TPR = perf@y.values)
colnames(roc_df) <- c("FPR", "TPR")
head(roc_df)

p1_1 <- ggplot(roc_df)+
  geom_line(aes(x=FPR, y=TPR))+theme_classic()+xlab("False positive rate")+ylab("True positive rate")+theme(text = element_text(family = "sans", size = 8))+
  geom_abline(intercept = 0, slope = 1, color = "grey50", linetype = "dashed")+ggtitle("Crohn's disease")+geom_text(x=0.9, y=0.05, label="AUC = 0.878", family = "sans", size = 3)

auc_ROCR <- performance(pred, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]] #0.8776596

###########################################################################################################################
#UC:
#Baseline model with default settings:
control <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"

#Search for best mtry and ntree:
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes

# train model
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1, 5, 10, 15, 20, 25, 30, 35), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom_UC <- train(Disease~., data=train_UC, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom_UC$results$Accuracy

control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom_UC1 <- train(Disease~., data=train_UC, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom_UC1$results$Accuracy

#Make a finer grid search:
tunegrid <- expand.grid(.mtry=seq(from =4, to = 30, by =2), .ntree=c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500))
set.seed(0)
custom_UC2 <- train(Disease~., data=train_UC, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom_UC2$results$Accuracy

#The results from the grid search:
df <- data.frame(mtry = c(rep(1, 4), rep(5, 4), rep(10, 4), rep(15, 4), rep(20, 4), rep(25, 4), rep(30, 4), rep(35, 4)), ntree = as.factor(rep(c(1000, 1500, 2000, 2500), 8)), Accuracy = c(0.6602582, 0.6638296, 0.6599997, 0.6590145, 0.6883689, 0.6874308, 0.6933954, 0.6932600, 0.6909293, 0.6896476, 0.6883720, 0.6932251, 0.6908913, 0.6893541, 0.6896065, 0.6946299, 0.6885483, 0.6872256, 0.6826720, 0.6862495, 0.6882518, 0.6835660, 0.6884632, 0.6873107, 0.6836100, 0.6919966, 0.6885514, 0.6859971, 0.6860822, 0.6791887, 0.6825458, 0.6897008))

df1 <- data.frame(mtry = c(rep(40, 4), rep(50, 4), rep(60, 4), rep(70, 4), rep(80, 4), rep(90, 4), rep(100, 4), rep(110, 4), rep(120, 4), rep(130, 4), rep(140, 4), rep(150, 4)), ntree = as.factor(rep(c(1000, 1500, 2000, 2500), 12)), Accuracy = c(0.6922079, 0.6814055, 0.6802560, 0.6921258, 0.6826400, 0.6862115, 0.6826339, 0.6802530, 0.6799124, 0.6789363, 0.6873639, 0.6822554, 0.6778249, 0.6825138, 0.6740832, 0.6849358, 0.6790595, 0.6802530, 0.6764702, 0.6743386, 0.6730630, 0.6693593, 0.6742124, 0.6728897, 0.6848917, 0.6754880, 0.6813173, 0.6802150, 0.6766375, 0.6802530, 0.6728076, 0.6743417, 0.6814936, 0.6779602, 0.6790625, 0.6755291, 0.6790184, 0.6741683, 0.6695737, 0.6731481, 0.6728927, 0.6743797, 0.6754880, 0.6766375, 0.6752737, 0.6731481, 0.6754470, 0.6778310))

df2 <- data.frame(mtry = c(rep(4, 8), rep(6, 8), rep(8, 8), rep(10, 8), rep(12, 8), rep(14, 8), rep(16, 8), rep(18, 8), rep(20, 8), rep(22, 8), rep(24, 8), rep(26, 8), rep(28, 8), rep(30, 8)), ntree = as.factor(c(rep(c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500), 14))), Accuracy = c(0.6857705, 0.6884951, 0.6825017, 0.6801998, 0.6848446, 0.6919403, 0.6839476, 0.6871343, 0.6828392, 0.6931779, 0.6944156, 0.6825017, 0.6858146, 0.6873928, 0.6846682, 0.6882458, 0.6885833, 0.6944186, 0.6872225, 0.6849237, 0.6894362, 0.6884130, 0.6909262, 0.6895183, 0.6859849, 0.6872636, 0.6872666, 0.6870994, 0.6967995, 0.6861582, 0.6919434, 0.6871845, 0.6810968, 0.6898619, 0.6861613, 0.6848416, 0.6871374, 0.6920346, 0.6908821, 0.6910965, 0.6861613, 0.6933543, 0.6838594, 0.6946269, 0.6955650, 0.6945448, 0.6861202, 0.6848857, 0.6896917, 0.6896947, 0.6838655, 0.6978258, 0.6933513, 0.6861172, 0.6849678, 0.6837803, 0.6907559, 0.6933133, 0.6872666, 0.6863316, 0.6861643, 0.6932220, 0.6872286, 0.6897798, 0.6816077, 0.6837393, 0.6884221, 0.6859469, 0.6910935, 0.6873989, 0.6894834, 0.6860761, 0.6849708, 0.6767637, 0.6837773, 0.6859119, 0.6848857, 0.6860792, 0.6908441, 0.6956532, 0.6946299, 0.6919936, 0.6907210, 0.6872697, 0.6861643, 0.6871845, 0.6979961, 0.6956532, 0.6871876, 0.6824196, 0.6887156, 0.6898270, 0.6932753, 0.6873609, 0.6908031, 0.6860822, 0.6850179, 0.6862525, 0.6873138, 0.6851031, 0.6898619, 0.6837393, 0.6907179, 0.6887597, 0.6872697, 0.6861233, 0.6885514, 0.6896537, 0.6861263, 0.6897388, 0.6847625, 0.6955711))

df <-rbind(df, df1) 

ggplot(df)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()+geom_vline(xintercept = 4, linetype="dashed")+geom_vline(xintercept = 30, linetype="dashed")
df[which.max(df$Accuracy),]

ggplot(df2)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()
df2[which.max(df2$Accuracy),]

#Best settings:
best_mtry <- 24
best_ntree <- 2250

#After selecting the optimal model: Fit and investigate!
#RF:
set.seed(0)
old_colnames <- colnames(train_UC)
colnames(train_UC) <- paste0("col_", seq(ncol(train_UC))) 
train_UC$col_145 <- as.factor(train_UC$col_145)
rf <- randomForest(col_145~., data=train_UC, mtry=best_mtry, ntree = best_ntree) 
print(rf)

#Prediction and confusion matrix - training data:
p1 <- predict(rf, train_UC)
confusionMatrix(p1, train_UC$col_145)

#Prediction and confusion matrix - test data:
colnames(test_UC) <- paste0("col_", seq(ncol(test_UC))) 
test_UC$col_145 <- as.factor(test_UC$col_145)
p2 <- predict(rf, test_UC)
confusionMatrix(p2, test_UC$col_145)

#Number of nodes and variable importance:
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")

varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
imp_UC <- as.data.frame(importance(rf))
old_colnames <- old_colnames[c(1:144, 146:152)]
imp_UC$bugs <- old_colnames

best10_UC <- imp_UC[order(-imp_UC$MeanDecreaseGini),]
best10_UC <- best10_UC[1:10,]

# Model accuracy
observed.classes <- test_UC$col_145
accuracy <- mean(p2 == observed.classes) # 0.6725664

res_UC <- data.frame(p2, observed.classes)
res_UC <- res_UC %>% mutate(type = ifelse(p2=="UC" & observed.classes=="UC", "TP", ifelse(p2=="UC" & observed.classes=="HC", "FP", ifelse(p2=="HC" & observed.classes=="UC", "FN", "TN"))))

precision <- sum(res_UC$type=="TP") / (sum(res_UC$type=="FP") + sum(res_UC$type=="TP")) #Pr(disease|positive)
sensitivity <- sum(res_UC$type=="TP") / (sum(res_UC$type=="TP") + sum(res_UC$type=="FN")) #Pr(positive|disease)
specificity <- sum(res_UC$type=="TN") / (sum(res_UC$type=="TN") + sum(res_UC$type=="FP")) #Pr(negative|no disease)

accuracy #0.6725664
precision #0.74
sensitivity #0.6065574
specificity #0.75

#Make ROC curve:
predictions <- as.data.frame(predict(rf, test_UC, type = "prob"))
obs <- ifelse(observed.classes=="HC", 0, 1)
pred <- prediction(predictions$UC, obs)
perf <- performance(pred,"tpr","fpr")

roc_df <- data.frame(FPR = perf@x.values, TPR = perf@y.values)
colnames(roc_df) <- c("FPR", "TPR")
head(roc_df)

p1_2 <- ggplot(roc_df)+
  geom_line(aes(x=FPR, y=TPR))+theme_classic()+xlab("False positive rate")+ylab("True positive rate")+theme(text = element_text(family = "sans", size = 8))+
  geom_abline(intercept = 0, slope = 1, color = "grey50", linetype = "dashed")+ggtitle("Ulcerative colitis")+geom_text(x=0.9, y=0.05, label="AUC = 0.764", family = "sans", size = 3)


auc_ROCR <- performance(pred, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]] #0.7643443
```

## CD vs. UC:
### Prepare a test and a validation dataset:
```{r}
#Reduce the number to be tested! 
ps_sub <- subset_samples(ps_relab, !is.na(Disease))
ps_sub <- subset_samples(ps_sub, !is.na(geo_loc_name_country))
ps_sub <- subset_samples(ps_sub, !is.na(Host_Age))
ps_sub <- subset_samples(ps_sub, !is.na(host_sex))

genus <- as.data.frame(as.matrix(otu_table(ps_sub)))
genus[1:5, 1:5]
#Remove columns with no count in any sample:
genus1 <- genus[,colSums(genus)!=0]

#Remove columns, where the genus is present in less than 10% of the samples:
sum(sapply(genus1, function(x) sum(x==0)) / dim(genus1)[1]>0.90)
genus <- genus1[, sapply(genus1, function(x) sum(x==0)) / dim(genus1)[1]<0.90]

ps_relab_reduced <- phyloseq(otu_table(genus, taxa_are_rows=F), sample_data(ps_sub), tax_table(ps_sub))

#Balance datasets based on disease!
meta_data <- as.data.frame(as.matrix(sample_data(ps_relab_reduced)))
meta <- meta_data %>% filter(Disease !="HC")

#Remove projects with 0 IBD cases or 0 HC:
meta %>% dplyr::group_by(BioProject) %>% summarize(CD = sum(Disease == "CD"), UC = sum(Disease == "UC"))
meta <- meta %>% filter(BioProject %in% c("PRJEB11419", "PRJEB13680", "PRJEB33711", "PRJNA380944", "PRJNA391149", "PRJNA450340", "PRJNA757573"))

set.seed(0)
new_meta <- data.frame()
for (i in unique(meta$BioProject)){
  sub_CD <- meta %>% filter(BioProject==i) %>% filter(Disease == "CD")
  sub_UC <- meta %>% filter(BioProject==i) %>% filter(Disease == "UC")
  if (nrow(sub_CD) == nrow(sub_UC)){
    new_meta <- rbind(new_meta,sub_CD)
    new_meta <- rbind(new_meta,sub_UC)
  } else if (nrow(sub_CD) < nrow(sub_UC)){
    sub_UC <- sample_n(sub_UC, nrow(sub_CD))
    new_meta <- rbind(new_meta,sub_CD)
    new_meta <- rbind(new_meta,sub_UC)
  } else {
    sub_CD <- sample_n(sub_CD, nrow(sub_UC))
    new_meta <- rbind(new_meta,sub_CD)
    new_meta <- rbind(new_meta,sub_UC)   
  }
}

ps_new <- subset_samples(ps_relab_reduced, Run %in% new_meta$Run)

#Split dataset randomly:
otu <- as.data.frame(as.matrix(otu_table(ps_new)))
meta <- sample_data(ps_new)
meta <- as.data.frame(as.matrix(meta)) %>% dplyr::select(Disease, geo_loc_name_country_continent, Instrument, LibraryLayout, X16s_region, Host_Age, host_sex, N)
df_new <- cbind(otu, meta)
df_new$N <- as.numeric(df_new$N)
df_new$Host_Age <- as.numeric(df_new$Host_Age)

set.seed(0)
ind <- sample(2, nrow(df_new), replace = TRUE, prob = c(0.7, 0.3))
train_new <- df_new[ind==1,]
test_new <- df_new[ind==2,]
```

### Random Forest:
```{r}
## Start with CD:

#Baseline model with default settings:
control <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"

#Search for best mtry and ntree:
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes

# train model
tunegrid <- expand.grid(.mtry=c(15, 20, 25, 30, 35), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom <- train(Disease~., data=train_new, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom$results$Accuracy

tunegrid <- expand.grid(.mtry=c(40, 45, 50, 55, 60, 65, 70, 75), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom1 <- train(Disease~., data=train_new, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom1$results$Accuracy

tunegrid <- expand.grid(.mtry=c(80, 90, 100, 110, 120, 130, 140, 150), .ntree=c(1000, 1500, 2000, 2500))
set.seed(0)
custom2 <- train(Disease~., data=train_new, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom2$results$Accuracy

#Last grid search  - finer!:
tunegrid <- expand.grid(.mtry=seq(from =2, to = 42, by =2), .ntree=c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500))
set.seed(0)
custom3 <- train(Disease~., data=train_new, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom3$results$Accuracy

#Results from grid search:
df <- data.frame(mtry = c(rep(15,4), rep(20,4), rep(25,4), rep(30,4), rep(35,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),5)), Accuracy = c(0.6532749, 0.6341520, 0.6273099, 0.6378363, 0.6326608, 0.6359162, 0.6259064, 0.6414327, 0.6432846, 0.6462573, 0.6346784, 0.6362671, 0.6397661, 0.6306433, 0.6361696, 0.6380117, 0.6326608, 0.6379240, 0.6273977, 0.6362573))

df1 <- data.frame(mtry = c(rep(40,4), rep(45,4), rep(50,4), rep(55,4), rep(60,4), rep(65,4), rep(70,4), rep(75,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),8)), Accuracy = c(0.6482846, 0.6295127, 0.6293275, 0.6347758, 0.6484503, 0.6361696, 0.6309064, 0.6310819, 0.6342300, 0.6327583, 0.6255458, 0.6241520, 0.6414327, 0.6290643, 0.6378363, 0.6325634, 0.6328363, 0.6238986, 0.6293275, 0.6325828, 0.6328460, 0.6223099, 0.6204678, 0.6326706, 0.6359162, 0.6345127, 0.6308187, 0.6328363, 0.6206530, 0.6293372, 0.6291520, 0.6292398))

df2 <- data.frame(mtry = c(rep(80,4), rep(90,4), rep(100,4), rep(110,4), rep(120,4), rep(130,4), rep(140,4), rep(150,4)), ntree = as.factor(rep(c(1000,1500,2000,2500),8)), Accuracy = c(0.6256335, 0.6239766, 0.6221345, 0.6274951, 0.6291520, 0.6240643, 0.6256433, 0.6305458, 0.6238889, 0.6307407, 0.6325731, 0.6222222, 0.6293275, 0.6256433, 0.6360819, 0.6254678, 0.6171540, 0.6273099, 0.6238012, 0.6188012, 0.6343372, 0.6325731, 0.6292495, 0.6275828, 0.6288012, 0.6221345, 0.6360916, 0.6291520, 0.6253801, 0.6260039, 0.6341520, 0.6237135))

df3 <- data.frame(mtry = c(rep(2, 8), rep(4, 8), rep(6, 8), rep(8, 8), rep(10, 8), rep(12, 8), rep(14, 8), rep(16, 8), rep(18, 8), rep(20, 8), rep(22, 8), rep(24, 8), rep(26, 8), rep(28, 8), rep(30, 8), rep(32, 8), rep(34, 8), rep(36, 8), rep(38, 8), rep(40, 8), rep(42, 8)), ntree = as.factor(rep(c(750, 1000, 1250, 1500, 1750, 2000, 2250, 2500), 21)), Accuracy = c(0.6445906, 0.6359064, 0.6530117, 0.6427485, 0.6477485, 0.6341423, 0.6321345, 0.6359942, 0.6325731, 0.6497661, 0.6289669, 0.6495906, 0.6374756, 0.6359064, 0.6408187, 0.6477485, 0.6289669, 0.6445906, 0.6497661, 0.6532846, 0.6446784, 0.6359064, 0.6447661, 0.6411696, 0.6497661, 0.6428363, 0.6533626, 0.6291520, 0.6377485, 0.6395029, 0.6447661, 0.6429240, 0.6359064, 0.6378363, 0.6463450, 0.6360819, 0.6289766, 0.6359844, 0.6288889, 0.6464327, 0.6395029, 0.6429240, 0.6464327, 0.6360819, 0.6221345, 0.6427485, 0.6325731, 0.6427485, 0.6393275, 0.6410819, 0.6411696, 0.6412573, 0.6410819, 0.6409064, 0.6377485, 0.6398538, 0.6275634, 0.6381871, 0.6395906, 0.6518811, 0.6364327, 0.6343275, 0.6341520, 0.6291520, 0.6310819, 0.6414327, 0.6360819, 0.6414425, 0.6377485, 0.6256530, 0.6430117, 0.6363450, 0.6241618, 0.6255556, 0.6395029, 0.6345029, 0.6399415, 0.6345029, 0.6309844, 0.6377485, 0.6443275, 0.6345029, 0.6362573, 0.6363450, 0.6399415, 0.6293275, 0.6343275, 0.6362573, 0.6395906, 0.6380117, 0.6501170, 0.6363450, 0.6430117, 0.6276608, 0.6344152, 0.6413450, 0.6324756, 0.6239766, 0.6276511, 0.6429142, 0.6291520, 0.6273977, 0.6345029, 0.6310819, 0.6342398, 0.6433723, 0.6446784, 0.6327583, 0.6327485, 0.6430994, 0.6376608, 0.6310819, 0.6398538, 0.6430994, 0.6326608, 0.6361696, 0.6397758, 0.6310819, 0.6309064, 0.6364327, 0.6341520, 0.6307115, 0.6361696, 0.6416959, 0.6343275, 0.6344932, 0.6328363, 0.6344152, 0.6170468, 0.6309844, 0.6429240, 0.6380994, 0.6204678, 0.6276608, 0.6292398, 0.6311696, 0.6294152, 0.6446881, 0.6343275, 0.6415302, 0.6291520, 0.6273099, 0.6413548, 0.6277485, 0.6293372, 0.6275828, 0.6344152, 0.6312671, 0.6329240, 0.6363548, 0.6257310, 0.6326608, 0.6463450, 0.6363548, 0.6223977, 0.6308187, 0.6291520, 0.6446686, 0.6380994, 0.6361696, 0.6275731, 0.6358187, 0.6362476, 0.6344152, 0.6310916, 0.6293275, 0.6294055, 0.6293275))

df <- rbind(df, df1, df2)
ggplot(df)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()+geom_vline(xintercept = 42, linetype = "dashed")
df[which.max(df$Accuracy),]

ggplot(df3)+
  geom_line(aes(x=mtry, y=Accuracy, color=ntree))+theme_classic()
df3[which.max(df3$Accuracy),]

best_mtry <- 8
best_ntree <- 1250

#After selecting the optimal model: Fit and investigate!
#RF:
set.seed(0)
old_colnames <- colnames(train_new)
colnames(train_new) <- paste0("col_", seq(ncol(train_new))) 
train_new$col_145 <- as.factor(train_new$col_145)
rf <- randomForest(col_145~., data=train_new, mtry=best_mtry, ntree = best_ntree) 
print(rf)

#Prediction and confusion matrix - training data:
p1 <- predict(rf, train_new)
confusionMatrix(p1, train_new$col_145)

#Prediction and confusion matrix - test data:
colnames(test_new) <- paste0("col_", seq(ncol(test_new))) 
test_new$col_145 <- as.factor(test_new$col_145)
p2 <- predict(rf, test_new)
confusionMatrix(p2, test_new$col_145)

#Number of nodes and variable importance:
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")

varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
imp_new <- as.data.frame(importance(rf))
old_colnames <- old_colnames[c(1:144, 146:152)]
imp_new$bugs <- old_colnames

best10_new <- imp_new[order(-imp_new$MeanDecreaseGini),]
write.table(best10_new, paste0(path, "results/mean_Gini_CD_vs_UC.txt"))
best10_new <- best10_new[1:10,]

# Model accuracy
observed.classes <- test_new$col_145
accuracy <- mean(p2 == observed.classes) # 0.625

#Make ROC curve:
predictions <- as.data.frame(predict(rf, test_new, type = "prob"))
obs <- ifelse(observed.classes=="UC", 0, 1)
pred <- prediction(predictions$CD, obs)
perf <- performance(pred,"tpr","fpr")

roc_df <- data.frame(FPR = perf@x.values, TPR = perf@y.values)
colnames(roc_df) <- c("FPR", "TPR")
head(roc_df)

p4_1 <- ggplot(roc_df)+
  geom_line(aes(x=FPR, y=TPR))+theme_classic()+xlab("False positive rate")+ylab("True positive rate")+theme(text = element_text(family = "sans", size = 8))+
  geom_abline(intercept = 0, slope = 1, color = "grey50", linetype = "dashed")+geom_text(x=0.85, y=0.05, label="AUC = 0.635", family = "sans", size = 3)

auc_ROCR <- performance(pred, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]] #0.6350251
```


### Plot distribution of top 10:
```{r}
plot_CD <- rbind(train_CD, test_CD)
colnames(plot_CD) <- c(old_colnames[1:144], "Disease", old_colnames[145:151])
i <- best10_CD$bugs[4]
for (i in best10_CD$bugs){
  ps_sub <- plot_CD %>% dplyr::select(i, Disease)
  colnames(ps_sub)[1] <- "bug"
  
  ps_sub$Disease <- factor(ps_sub$Disease, levels=c("HC", "UC", "CD"))
  p1 <- ggplot(ps_sub)+
    geom_boxplot(aes(x=Disease, y=log(bug+1)))+xlab("")+ylab("Relative abundance")+ggtitle(gsub("_", " ", i))+theme_classic()
  print(p1)
}

plot_UC <- rbind(train_UC, test_UC)
colnames(plot_UC) <- c(old_colnames[1:144], "Disease", old_colnames[145:151])

for (i in best10_UC$bugs[c(1:5, 7:10)]){
  ps_sub <- plot_UC %>% dplyr::select(i, Disease)
  colnames(ps_sub)[1] <- "bug"
  
  ps_sub$Disease <- factor(ps_sub$Disease, levels=c("HC", "UC", "CD"))
  p1 <- ggplot(ps_sub)+
    geom_boxplot(aes(x=Disease, y=log(bug+1)))+xlab("")+ylab("Relative abundance")+ggtitle(gsub("_", " ", i))+theme_classic()
  print(p1)
}

ps_sub <- plot_UC %>% dplyr::select(Host_Age, Disease)
ps_sub$Disease <- factor(ps_sub$Disease, levels=c("HC", "UC", "CD"))
  
p1 <- ggplot(ps_sub)+
    geom_boxplot(aes(x=Disease, y=Host_Age))+xlab("")+ylab("Relative abundance")+ggtitle("Host age")+theme_classic()
p1

#Change the names to only be genus:
taxes <- as.data.frame(as.matrix(tax_table(ps_relab)))
head(taxes)
taxes$bugs <- row.names(taxes)
best_10_CD <- left_join(best10_CD, taxes, by="bugs")
best_10_UC <- left_join(best10_UC, taxes, by="bugs")

best_10_CD$sign <- c("-", "-", "+", "-", "+", "-", "-", "+", "-", "-")
best_10_UC$sign <- c("-", "-", "-", "-", "-", "+", "-", "-", "-", "-")

best_10_UC[6, "Genus"] <- "Host age"


colorBlindGrey8   <- c("#009E73", "#56B4E9", "#E69F00", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999")

#Plot together the best10 variable importance:
p2_1 <- ggplot(best_10_CD)+
  geom_col(aes(x=MeanDecreaseGini, y=reorder(Genus, MeanDecreaseGini), fill=sign))+theme_classic()+xlab("Mean decrease in Gini")+ylab("")+ggtitle("Crohn's disease")+ scale_fill_manual(values=c("#009E73", "#D55E00"))+theme(legend.position = "none")+xlim(c(0,7))+theme(text = element_text(family = "sans", size = 8), axis.text.y = element_text(face="italic"))

p2_2 <- ggplot(best_10_UC)+
  geom_col(aes(x=MeanDecreaseGini, y=reorder(Genus, MeanDecreaseGini), fill=sign))+theme_classic()+xlab("Mean decrease in Gini")+ylab("")+ggtitle("Ulcerative colitis")+ scale_fill_manual(values=c("#009E73", "#D55E00"))+theme(legend.position = "none")+xlim(c(0,7))+theme(text = element_text(family = "sans", size = 8), axis.text.y = element_text(face="italic"))

#Combine all plots:
p_top <- ggarrange(p1_1, p1_2, labels=c("A)", "B)"), font.label = list(size=10, family="sans")) 
p_bottom <- ggarrange(p2_1, p2_2, labels="C)", font.label = list(size=10, family="sans"), ncol=1, nrow=2)

p_total <- ggarrange(p_top, p_bottom, ncol=1, nrow=2, heights=c(0.7, 1))

ggsave(p_total, filename = paste0(path, "illustrations/IBD_project/Figure3.tiff"), width = 174, height = 175, units = "mm", dpi=300)

####################################
#CD vs UC:
plot_new <- rbind(train_new, test_new)
colnames(plot_new) <- c(old_colnames[1:144], "Disease", old_colnames[145:151])

for (i in best10_new$bugs){
  ps_sub <- plot_new %>% dplyr::select(i, Disease)
  colnames(ps_sub)[1] <- "bug"
  
  ps_sub$Disease <- factor(ps_sub$Disease, levels=c("HC", "UC", "CD"))
  p1 <- ggplot(ps_sub)+
    geom_boxplot(aes(x=Disease, y=log(bug+1)))+xlab("")+ylab("Relative abundance")+ggtitle(gsub("_", " ", i))+theme_classic()
  print(p1)
}


#Change the names to only be genus:
best_10_new <- left_join(best10_new, taxes, by="bugs")

best_10_new$sign <- c("-", "-", "-", "-", "-", "-", "+", "+", "-", "-")

#Plot together the best10 variable importance:
p4_2 <- ggplot(best_10_new)+
  geom_col(aes(x=MeanDecreaseGini, y=reorder(Genus, MeanDecreaseGini), fill=sign))+theme_classic()+xlab("Mean decrease in Gini")+ylab("")+ scale_fill_manual(values=c("#009E73", "#D55E00"))+theme(legend.position = "none")+theme(text = element_text(family = "sans", size = 8), axis.text.y = element_text(face="italic"))

p4 <- ggarrange(p4_1, p4_2, labels=c("A)", "B)"), font.label = list(size=10, family="sans"), widths = c(0.7, 1))

ggsave(p4, filename = paste0(path, "illustrations/IBD_project/Figure4.tiff"), width = 174, height = 70, units = "mm", dpi=300)
```
